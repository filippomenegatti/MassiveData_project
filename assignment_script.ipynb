{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "massivedata_assignment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6C471RiOx2JIU1SO6/tJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filippomenegatti/MassiveData_project/blob/main/assignment_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vLLMVbmQS_W"
      },
      "source": [
        "The task is to implement a system finding frequent itemsets (aka market-basket analysis), analyzing one of the two datasets described below.  \r\n",
        "The «Old Newspapers» dataset is published on Kaggle and released under the public domain license (CC0). The analysis must be done considering values of the Text attribute as baskets and words as items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuL6utVR51NV"
      },
      "source": [
        "from google.colab import files\r\n",
        "\r\n",
        "files.upload() #import the kaggle.json file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qicIP4O51V9"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d alvations/old-newspapers\n",
        "!mkdir assignment\n",
        "!unzip old-newspapers.zip -d assignment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z10XKlLX4Lqh"
      },
      "source": [
        "Import PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__ZlnK_736VN"
      },
      "source": [
        "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\r\n",
        "# !wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\r\n",
        "# !tar xf spark-3.1.1-bin-hadoop2.7.tgz\r\n",
        "# !pip install -q findspark\r\n",
        "# !pip install -q pyspark\r\n",
        "# !pip install -q koalas\r\n",
        "# import os\r\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\r\n",
        "# import findspark\r\n",
        "# findspark.init(\"/content/spark-3.1.1-bin-hadoop2.7\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBEonPfLk0L7"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f23nBanZNhxs"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "\r\n",
        "spark = SparkSession \\\r\n",
        "        .builder \\\r\n",
        "        .master(\"local[*]\") \\\r\n",
        "        .config(\"spark.sql.execution.arrow.enabled\", \"true\") \\\r\n",
        "        .config(\"spark.sql.execution.arrow.fallback.enabled\", \"true\") \\\r\n",
        "        .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5yk1uEuUBe4"
      },
      "source": [
        "Trying to understand the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOjeSBcn_ngV"
      },
      "source": [
        "newspapers = '/content/assignment/old-newspaper.tsv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmUqqTvdSyIv"
      },
      "source": [
        "# df = spark.read \\\n",
        "#   .options(header = True, sep= r'\\t') \\\n",
        "#   .csv(newspapers)\n",
        "# df2 = df.drop('Source', 'Date')\n",
        "# df3 = df2.where(df.Language == 'English').select('Text')\n",
        "# df3.select('Text').limit(5).toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLbUcFLljnYK"
      },
      "source": [
        "dataRDD = spark.sparkContext.textFile(newspapers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSnhXj39y74L"
      },
      "source": [
        "def take_eng_sentences(text):\r\n",
        "  item = text.split('\\t')\r\n",
        "  if item[0] == 'English':\r\n",
        "    return item[3]\r\n",
        "  else:\r\n",
        "    pass "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EUg-Rr4yEMG"
      },
      "source": [
        "sentences = dataRDD.map(take_eng_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0OttITu-Zxe"
      },
      "source": [
        "eng_sentences = sentences.filter(lambda x: x is not None) #it works!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHxovt94Eq1I"
      },
      "source": [
        "def lower_clean_str(text):\r\n",
        "  punc='!\"#$%&\\()*+,-./:;<=>?@[\\]^_`{|}~0123456789' #we do not remove apostrophes because it makes a mess with many words\r\n",
        "  lowercased_str = text.lower()\r\n",
        "  for ch in punc:\r\n",
        "    lowercased_str = lowercased_str.replace(ch, '')\r\n",
        "  return lowercased_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh8QerH9Et5S"
      },
      "source": [
        "no_punct = eng_sentences.map(lower_clean_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j9j51desN4G"
      },
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n",
        "remover = StopWordsRemover()\n",
        "stopwords = remover.getStopWords()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsi9ljN-yEHo"
      },
      "source": [
        "def dupstops_remover(text):\r\n",
        "  l = text.split() \r\n",
        "  k = [] \r\n",
        "  for i in l:  \r\n",
        "    if (text.count(i) > 1 and (i not in k) or text.count(i) == 1) and i not in stopwords: \r\n",
        "        k.append(i) \r\n",
        "  return k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8ObWqXp5GE_"
      },
      "source": [
        "items = no_punct.map(dupstops_remover)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIqEEJMLSGCT"
      },
      "source": [
        "## Trying with Apriori Algorithm?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01K2zIkISFsL"
      },
      "source": [
        "list_items = items.flatMap(lambda line: line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_maRouBiSPaW"
      },
      "source": [
        "uniqueItems = list_items.distinct()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMArCpJCSPQe"
      },
      "source": [
        "supportRdd = list_items.map(lambda item: (item , 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMJZpAGDWcCz"
      },
      "source": [
        "# Method for sum in reduceByKey method\r\n",
        "def sumOperator(x,y):\r\n",
        "    return x+y\r\n",
        "\r\n",
        "# Sum of values by key\r\n",
        "supportRdd = supportRdd.reduceByKey(sumOparator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6la4CRmtWb89"
      },
      "source": [
        "# First support values\r\n",
        "supports = supportRdd.map(lambda item: item[1]) # Return only support values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRRtEUTOUO-1"
      },
      "source": [
        "minSupport = supports.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Zk8q_G0YXs"
      },
      "source": [
        "minSupport = 5 if minSupport == 1 else minSupport"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtqlaRE10Oi9",
        "outputId": "9e0db043-035e-4d00-c403-803eb6c013ec"
      },
      "source": [
        "print(minSupport)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7xNUDGuUO7i"
      },
      "source": [
        "supportRdd = supportRdd.filter(lambda item: item[1] >= minSupport)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcrhTlOZUO4F",
        "outputId": "e09388d7-0424-4502-d89b-1d0aadf7b06b"
      },
      "source": [
        "## Craete base RDD with will be updated every iteration\r\n",
        "baseRdd = supportRdd.map(lambda item: ([item[0]] , item[1])) \r\n",
        "print('1 . Table has created...') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 . Table has created...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oT248Foxudm"
      },
      "source": [
        "supportRdd = supportRdd.map(lambda item: item[0])\r\n",
        "supportRddCart = supportRdd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7kNFCzKxuaL"
      },
      "source": [
        "def removeReplica(record):\r\n",
        "\r\n",
        "    if(isinstance(record[0], tuple)):\r\n",
        "        x1 = record[0]\r\n",
        "        x2 = record[1]\r\n",
        "    else:\r\n",
        "        x1 = [record[0]]\r\n",
        "        x2 = record[1]\r\n",
        "\r\n",
        "    if(any(x == x2 for x in x1) == False):\r\n",
        "        a = list(x1)\r\n",
        "        a.append(x2)\r\n",
        "        a.sort()\r\n",
        "        result = tuple(a)\r\n",
        "        return result \r\n",
        "    else:\r\n",
        "        return x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nut6rRtxuXS"
      },
      "source": [
        "c = 2 # Combination length \r\n",
        "\r\n",
        "while(supportRdd.isEmpty() == False):\r\n",
        "\r\n",
        "    combined = supportRdd.cartesian(uniqueItems)\r\n",
        "    combined = combined.map(lambda item: removeReplica(item))\r\n",
        "  \r\n",
        "    combined = combined.filter(lambda item: len(item) == c)\r\n",
        "    combined = combined.distinct()\r\n",
        "\r\n",
        "    \r\n",
        "    combined_2 = combined.cartesian(items)\r\n",
        "    combined_2 = combined_2.filter(lambda item: all(x in item[1] for x in item[0]))\r\n",
        "    \r\n",
        "    combined_2 = combined_2.map(lambda item: item[0])\r\n",
        "    combined_2 = combined_2.map(lambda item: (item , 1))\r\n",
        "    combined_2 = combined_2.reduceByKey(sumOperator)\r\n",
        "    combined_2 = combined_2.filter(lambda item: item[1] >= minSupport)\r\n",
        "\r\n",
        "    baseRdd = baseRdd.union(combined_2)\r\n",
        "    \r\n",
        "    combined_2 = combined_2.map(lambda item: item[0])\r\n",
        "    supportRdd = combined_2\r\n",
        "    print(c ,'. Table has crated... ')\r\n",
        "    c = c+1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZy06GiCzEQr"
      },
      "source": [
        "class Filter():\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        \r\n",
        "        self.stages = 1\r\n",
        "\r\n",
        "\r\n",
        "    def filterForConf(self, item , total):\r\n",
        "        \r\n",
        "        if(len(item[0][0]) > len(item[1][0])  ):\r\n",
        "            if(self.checkItemSets(item[0][0] , item[1][0]) == False):\r\n",
        "                pass\r\n",
        "            else:\r\n",
        "                return (item)       \r\n",
        "        else:\r\n",
        "            pass  \r\n",
        "        self.stages = self.stages + 1\r\n",
        "\r\n",
        "    # Check Items sets includes at least one comman item // Example command: # any(l == k for k in z for l in x )\r\n",
        "    def checkItemSets(self, item_1 , item_2):\r\n",
        "\r\n",
        "        if(len(item_1) > len(item_2)):\r\n",
        "            return all(any(k == l for k in item_1 ) for l in item_2)\r\n",
        "        else:\r\n",
        "            return all(any(k == l for k in item_2 ) for l in item_1)\r\n",
        "\r\n",
        "\r\n",
        "    def calculateConfidence(self, item):\r\n",
        "\r\n",
        "        # Parent item list\r\n",
        "        parent = set(item[0][0])\r\n",
        "        \r\n",
        "        # Child item list\r\n",
        "        if(isinstance(item[1][0] , str)):\r\n",
        "            child  = set([item[1][0]])\r\n",
        "        else:\r\n",
        "            child  = set(item[1][0])\r\n",
        "        # Parent and Child support values\r\n",
        "        parentSupport = item[0][1]\r\n",
        "        childSupport = item[1][1]\r\n",
        "        # Finds the item set confidence is going to be found\r\n",
        "\r\n",
        "        support = (parentSupport / childSupport)*100\r\n",
        "\r\n",
        "        return list([ list(child) ,  list(parent.difference(child)) , support ])\r\n",
        "\r\n",
        "        \r\n",
        "# Example ((('x10', 'x3', 'x6', 'x7', 'x9'), 1), (('x10', 'x3', 'x7'), 1))\r\n",
        "calcuItems = baseRdd.cartesian(baseRdd)\r\n",
        "\r\n",
        "# Create Filter Object\r\n",
        "ff = Filter()\r\n",
        "\r\n",
        "#deneme = calcuItems.map(lambda item: lens(item)) \r\n",
        "total = calcuItems.count()\r\n",
        "\r\n",
        "print('# : Aggregated support values preparing for the confidence calculatations')\r\n",
        "baseRddConfidence = calcuItems.filter(lambda item: ff.filterForConf(item , total))\r\n",
        "print('# : Aggregated support values are ready !')\r\n",
        "baseRddConfidence = baseRddConfidence.map(lambda item: ff.calculateConfidence(item))\r\n",
        "\r\n",
        "  \r\n",
        "print(baseRddConfidence.collect())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y6wdrz3mgqn"
      },
      "source": [
        "## Other try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJe8X_ngYG6T"
      },
      "source": [
        "df = items.map(lambda x: [x]).toDF(['words'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1MFEe4qZKVD",
        "outputId": "e20c5d51-7367-46af-81f4-41c7616aa04d"
      },
      "source": [
        "df.limit(5).show(truncate = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|words                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[home, alone, apparently]                                                                                                                                                                                                                                                                                                                                                              |\n",
            "|[st, louis, plant, close, die, old, age, workers, making, cars, since, onset, mass, automotive, production]                                                                                                                                                                                                                                                                            |\n",
            "|[wsu's, plans, quickly, became, hot, topic, local, online, sites, though, people, applauded, new, biomedical, center, many, deplored, potential, loss, building]                                                                                                                                                                                                                       |\n",
            "|[alaimo, group, mount, holly, contract, last, fall, evaluate, suggest, improvements, trenton, water, works, campaign, finance, records, released, week, show, two, employees, donated, total, political, action, committee, pac, partners, progress, early, june, reported, gave, direct, inkind, contributions, mayor, tony, mack, weeks, leading, victory, mayoral, runoff, election]|\n",
            "|[often, difficult, predict, law's, impact, legislators, think, twice, carrying, bill, absolutely, necessary, issue, serious, enough, merit, attention, definitely, make, situation, worse]                                                                                                                                                                                             |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-SH59yKnsdr"
      },
      "source": [
        "from pyspark.ml.fpm import FPGrowth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE_zUuEpkmqH"
      },
      "source": [
        "fpGrowth = FPGrowth(itemsCol='words', minSupport= 0.01, numPartitions= 1000, minConfidence= 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuitR-64mbUj"
      },
      "source": [
        "model2 = fpGrowth.fit(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9urkQuhWbVv",
        "outputId": "a041f990-9dd1-47e9-c2eb-508fec990e8f"
      },
      "source": [
        "model2.freqItemsets.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|       items|  freq|\n",
            "+------------+------+\n",
            "|      [said]|227814|\n",
            "|       [one]| 75382|\n",
            "| [one, said]| 17227|\n",
            "|       [new]| 62422|\n",
            "| [new, said]| 12750|\n",
            "|      [also]| 56582|\n",
            "|[also, said]| 11355|\n",
            "|       [two]| 52666|\n",
            "|      [year]| 51366|\n",
            "|[year, said]| 11417|\n",
            "+------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn5fJ3eMQDea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4285ad7d-9769-4762-8049-ee5f13bddf4f"
      },
      "source": [
        "model2.associationRules.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----------+-------------------+------------------+--------------------+\n",
            "|antecedent|consequent|         confidence|              lift|             support|\n",
            "+----------+----------+-------------------+------------------+--------------------+\n",
            "|     [one]|    [said]|0.22852935714096204| 1.013414253807052|0.017052349833010308|\n",
            "|    [said]|     [one]|0.07561870648862669| 1.013414253807052|0.017052349833010308|\n",
            "|    [said]|     [new]|0.05596670968421607|0.9057691314729072|  0.0126207383973345|\n",
            "|    [said]|    [also]|0.04984329321288419|0.8899259167574591|0.011239881137390844|\n",
            "|    [said]|    [year]| 0.0501154450560545|0.9856466815465212|0.011301252571166117|\n",
            "|    [said]|    [last]|0.04601560922506957|0.9543017489120509|0.010376721617196672|\n",
            "|    [said]|    [time]|0.05584819194606126|   1.1926645484288|0.012594012127787203|\n",
            "|    [said]|    [like]|0.05966709684216071|1.3545360160000477|0.013455191924311204|\n",
            "|    [said]|  [people]|0.06897293406024213|  1.64917646566678| 0.01555369901469153|\n",
            "|    [said]|   [state]|0.04454072181692082|1.0699792621336786|0.010044128040608093|\n",
            "+----------+----------+-------------------+------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}